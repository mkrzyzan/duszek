# GROQ API Configuration
# Get your free API key from: https://console.groq.com

GROQ_API_KEY=your_groq_api_key_here

# Optional: Choose your model (default: llama-3.3-70b-versatile)
# Available models (as of Feb 2026):
# - llama-3.3-70b-versatile (recommended, fast and capable)
# - llama-3.1-8b-instant (ultra fast, lighter)
# - meta-llama/llama-4-scout-17b-16e-instruct (newer model)
# - meta-llama/llama-4-maverick-17b-128e-instruct (newer model)
# - groq/compound (Groq's own model)
# - openai/gpt-oss-120b (large model)
# See full list: https://console.groq.com/docs/models

MODEL=llama-3.3-70b-versatile

# Optional: Enable debug mode for detailed error messages
# Set to 'true' or '1' to enable
# You can also use --debug flag when running: node index.js --debug "your query"

DEBUG=false
